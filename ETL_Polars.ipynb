{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWHx4RteDP-T"
      },
      "outputs": [],
      "source": [
        "# ETL con Polars en Google Colab\n",
        "# Instalar Polars (ejecutar solo una vez)\n",
        "# !pip install polars\n",
        "\n",
        "import polars as pl\n",
        "from datetime import datetime, timedelta\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXTRACT - Extracci√≥n de datos\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FASE 1: EXTRACT - Extracci√≥n de datos\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Simular datos de ventas (en un caso real, leer√≠as desde CSV, API, DB, etc.)\n",
        "n_records = 1000\n",
        "start_date = datetime(2024, 1, 1)\n",
        "\n",
        "data = {\n",
        "    \"id_venta\": range(1, n_records + 1),\n",
        "    \"fecha\": [(start_date + timedelta(days=random.randint(0, 365))).strftime(\"%Y-%m-%d\")\n",
        "              for _ in range(n_records)],\n",
        "    \"producto\": [random.choice([\"Laptop\", \"Mouse\", \"Teclado\", \"Monitor\", \"Webcam\"])\n",
        "                 for _ in range(n_records)],\n",
        "    \"cantidad\": [random.randint(1, 10) for _ in range(n_records)],\n",
        "    \"precio_unitario\": [round(random.uniform(10, 1000), 2) for _ in range(n_records)],\n",
        "    \"cliente\": [f\"Cliente_{random.randint(1, 100)}\" for _ in range(n_records)],\n",
        "    \"region\": [random.choice([\"Norte\", \"Sur\", \"Este\", \"Oeste\", None]) for _ in range(n_records)],\n",
        "    \"estado\": [random.choice([\"Completado\", \"Pendiente\", \"Cancelado\"]) for _ in range(n_records)]\n",
        "}\n",
        "\n",
        "# Crear DataFrame de Polars\n",
        "df_raw = pl.DataFrame(data)\n",
        "\n",
        "print(f\"\\n‚úì Datos extra√≠dos: {df_raw.shape[0]} registros, {df_raw.shape[1]} columnas\")\n",
        "print(\"\\nPrimeras 5 filas:\")\n",
        "print(df_raw.head())\n",
        "print(\"\\nInformaci√≥n del DataFrame:\")\n",
        "print(df_raw.describe())"
      ],
      "metadata": {
        "id": "6kfvGW5HDgc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# TRANSFORM - Transformaci√≥n de datos\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FASE 2: TRANSFORM - Transformaci√≥n de datos\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Convertir fecha a tipo datetime\n",
        "df_transformed = df_raw.with_columns([\n",
        "    pl.col(\"fecha\").str.to_date().alias(\"fecha\")\n",
        "])\n",
        "\n",
        "# 2. Crear columna de total de venta\n",
        "df_transformed = df_transformed.with_columns([\n",
        "    (pl.col(\"cantidad\") * pl.col(\"precio_unitario\")).alias(\"total_venta\")\n",
        "])\n",
        "\n",
        "# 3. Filtrar solo ventas completadas\n",
        "df_transformed = df_transformed.filter(pl.col(\"estado\") == \"Completado\")\n",
        "\n",
        "# 4. Manejar valores nulos en regi√≥n (rellenar con \"No Especificado\")\n",
        "df_transformed = df_transformed.with_columns([\n",
        "    pl.col(\"region\").fill_null(\"No Especificado\")\n",
        "])\n",
        "\n",
        "# 5. Extraer informaci√≥n temporal\n",
        "df_transformed = df_transformed.with_columns([\n",
        "    pl.col(\"fecha\").dt.year().alias(\"a√±o\"),\n",
        "    pl.col(\"fecha\").dt.month().alias(\"mes\"),\n",
        "    pl.col(\"fecha\").dt.quarter().alias(\"trimestre\")\n",
        "])\n",
        "\n",
        "# 6. Categorizar ventas por monto\n",
        "df_transformed = df_transformed.with_columns([\n",
        "    pl.when(pl.col(\"total_venta\") < 100)\n",
        "    .then(pl.lit(\"Baja\"))\n",
        "    .when(pl.col(\"total_venta\") < 500)\n",
        "    .then(pl.lit(\"Media\"))\n",
        "    .otherwise(pl.lit(\"Alta\"))\n",
        "    .alias(\"categoria_venta\")\n",
        "])\n",
        "\n",
        "print(f\"\\n‚úì Datos transformados: {df_transformed.shape[0]} registros\")\n",
        "print(\"\\nPrimeras 5 filas transformadas:\")\n",
        "print(df_transformed.head())\n"
      ],
      "metadata": {
        "id": "HmzcUKX1D2Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# AGREGACIONES Y AN√ÅLISIS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"AGREGACIONES Y AN√ÅLISIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Ventas por producto\n",
        "ventas_producto = (\n",
        "    df_transformed\n",
        "    .group_by(\"producto\")\n",
        "    .agg([\n",
        "        pl.count().alias(\"num_ventas\"),\n",
        "        pl.sum(\"cantidad\").alias(\"cantidad_total\"),\n",
        "        pl.sum(\"total_venta\").alias(\"ingreso_total\"),\n",
        "        pl.mean(\"total_venta\").alias(\"ticket_promedio\")\n",
        "    ])\n",
        "    .sort(\"ingreso_total\", descending=True)\n",
        ")\n",
        "\n",
        "print(\"\\nüìä Ventas por Producto:\")\n",
        "print(ventas_producto)\n",
        "\n",
        "# Ventas por regi√≥n y mes\n",
        "ventas_region_mes = (\n",
        "    df_transformed\n",
        "    .group_by([\"region\", \"mes\"])\n",
        "    .agg([\n",
        "        pl.count().alias(\"num_ventas\"),\n",
        "        pl.sum(\"total_venta\").alias(\"ingreso_total\")\n",
        "    ])\n",
        "    .sort([\"region\", \"mes\"])\n",
        ")\n",
        "\n",
        "print(\"\\nüìä Ventas por Regi√≥n y Mes (primeras 10):\")\n",
        "print(ventas_region_mes.head(10))\n"
      ],
      "metadata": {
        "id": "WdbfwKmcD4El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LOAD - Carga de datos\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FASE 3: LOAD - Carga de datos\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Guardar datos transformados\n",
        "df_transformed.write_csv(\"ventas_transformadas.csv\")\n",
        "print(\"‚úì Archivo CSV guardado: ventas_transformadas.csv\")\n",
        "\n",
        "# Guardar agregaciones\n",
        "ventas_producto.write_csv(\"ventas_por_producto.csv\")\n",
        "print(\"‚úì Archivo CSV guardado: ventas_por_producto.csv\")\n",
        "\n",
        "ventas_region_mes.write_csv(\"ventas_por_region_mes.csv\")\n",
        "print(\"‚úì Archivo CSV guardado: ventas_por_region_mes.csv\")\n",
        "\n",
        "# Guardar en formato Parquet (m√°s eficiente)\n",
        "df_transformed.write_parquet(\"ventas_transformadas.parquet\")"
      ],
      "metadata": {
        "id": "hSwXeBBqD9GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# RESUMEN DEL ETL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RESUMEN DEL ETL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "üìà Estad√≠sticas Finales:\n",
        "  - Registros originales: {df_raw.shape[0]}\n",
        "  - Registros procesados: {df_transformed.shape[0]}\n",
        "  - Registros descartados: {df_raw.shape[0] - df_transformed.shape[0]}\n",
        "  - Columnas finales: {df_transformed.shape[1]}\n",
        "  - Ingreso total: ${df_transformed['total_venta'].sum():,.2f}\n",
        "  - Ticket promedio: ${df_transformed['total_venta'].mean():,.2f}\n",
        "  - Per√≠odo analizado: {df_transformed['fecha'].min()} a {df_transformed['fecha'].max()}\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n‚úÖ ETL completado exitosamente!\")"
      ],
      "metadata": {
        "id": "oUILUW2NEBsf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}