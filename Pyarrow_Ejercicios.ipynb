{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Tutorial PyArrow en Google Colab\n",
        "# Copia este código en celdas separadas de Colab\n",
        "\n",
        "# ============================================\n",
        "# Verificar instalación\n",
        "# ============================================\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pyarrow.compute as pc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(f\"✅ PyArrow versión: {pa.__version__}\")"
      ],
      "metadata": {
        "id": "Pfs6kmS44npu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Crear datos de ejemplo\n",
        "# ============================================\n",
        "# Crear un dataset de ventas\n",
        "np.random.seed(42)\n",
        "\n",
        "datos_ventas = {\n",
        "    'fecha': pd.date_range('2025-01-01', periods=1000, freq='H'),\n",
        "    'producto': np.random.choice(['Laptop', 'Mouse', 'Teclado', 'Monitor'], 1000),\n",
        "    'cantidad': np.random.randint(1, 20, 1000),\n",
        "    'precio': np.random.uniform(10, 1000, 1000).round(2),\n",
        "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], 1000)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(datos_ventas)\n",
        "print(\"📊 Dataset creado:\")\n",
        "print(df.head())\n",
        "print(f\"\\nDimensiones: {df.shape}\")"
      ],
      "metadata": {
        "id": "TLwlpkV34wfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Convertir a PyArrow Table\n",
        "# ============================================\n",
        "tabla = pa.Table.from_pandas(df)\n",
        "\n",
        "print(\"🔄 Tabla PyArrow:\")\n",
        "print(tabla)\n",
        "print(f\"\\nSchema:\")\n",
        "print(tabla.schema)\n"
      ],
      "metadata": {
        "id": "ZTvhG5OK6hcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Guardar en Parquet\n",
        "# ============================================\n",
        "# Guardar en formato Parquet\n",
        "pq.write_table(tabla, 'ventas.parquet', compression='snappy')\n",
        "\n",
        "# Verificar el tamaño del archivo\n",
        "import os\n",
        "tamaño_mb = os.path.getsize('ventas.parquet') / (1024 * 1024)\n",
        "print(f\"💾 Archivo guardado: ventas.parquet ({tamaño_mb:.2f} MB)\")"
      ],
      "metadata": {
        "id": "i9GY_TT_6q60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Leer desde Parquet\n",
        "# ============================================\n",
        "tabla_leida = pq.read_table('ventas.parquet')\n",
        "print(\"📖 Tabla leída desde Parquet:\")\n",
        "print(f\"Filas: {tabla_leida.num_rows}\")\n",
        "print(f\"Columnas: {tabla_leida.num_columns}\")\n",
        "\n",
        "# Leer solo algunas columnas\n",
        "tabla_parcial = pq.read_table('ventas.parquet', columns=['producto', 'cantidad', 'precio'])\n",
        "print(f\"\\n📋 Lectura parcial (solo 3 columnas): {tabla_parcial.column_names}\")"
      ],
      "metadata": {
        "id": "uERFU8826upV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Operaciones de filtrado\n",
        "# ============================================\n",
        "# Filtrar ventas de Laptops con cantidad > 10\n",
        "mascara = pc.and_(\n",
        "    pc.equal(tabla['producto'], 'Laptop'),\n",
        "    pc.greater(tabla['cantidad'], 10)\n",
        ")\n",
        "\n",
        "ventas_filtradas = tabla.filter(mascara)\n",
        "print(f\"🔍 Ventas de Laptops con cantidad > 10: {ventas_filtradas.num_rows} registros\")\n",
        "print(ventas_filtradas.to_pandas().head())"
      ],
      "metadata": {
        "id": "YVpAmt_I68Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Agregar columna calculada\n",
        "# ============================================\n",
        "# Calcular ingresos totales\n",
        "ingresos = pc.multiply(tabla['cantidad'], tabla['precio'])\n",
        "tabla_con_ingresos = tabla.append_column('ingresos', ingresos)\n",
        "\n",
        "print(\"💰 Tabla con columna 'ingresos' agregada:\")\n",
        "print(tabla_con_ingresos.column_names)\n",
        "print(tabla_con_ingresos.to_pandas().head())\n"
      ],
      "metadata": {
        "id": "UHPzcgv78MLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Estadísticas y agregaciones\n",
        "# ============================================\n",
        "print(\"📈 Estadísticas de ventas:\")\n",
        "print(f\"Total ingresos: ${pc.sum(ingresos).as_py():,.2f}\")\n",
        "print(f\"Promedio ingresos: ${pc.mean(ingresos).as_py():,.2f}\")\n",
        "print(f\"Mínimo: ${pc.min(ingresos).as_py():,.2f}\")\n",
        "print(f\"Máximo: ${pc.max(ingresos).as_py():,.2f}\")\n",
        "\n",
        "# Contar ventas por producto\n",
        "productos_unicos = pc.unique(tabla['producto'])\n",
        "print(f\"\\nProductos únicos: {productos_unicos.to_pylist()}\")\n"
      ],
      "metadata": {
        "id": "Qh9n1qyt8eFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Trabajar con múltiples archivos\n",
        "# ============================================\n",
        "# Crear archivos particionados por región\n",
        "for region in ['Norte', 'Sur', 'Este', 'Oeste']:\n",
        "    mascara_region = pc.equal(tabla_con_ingresos['region'], region)\n",
        "    tabla_region = tabla_con_ingresos.filter(mascara_region)\n",
        "    pq.write_table(tabla_region, f'ventas_{region}.parquet')\n",
        "    print(f\"✅ Guardado: ventas_{region}.parquet ({tabla_region.num_rows} filas)\")"
      ],
      "metadata": {
        "id": "WasXnazl8hux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Leer múltiples archivos con Dataset\n",
        "# ============================================\n",
        "import pyarrow.dataset as ds\n",
        "\n",
        "# Leer todos los archivos de ventas\n",
        "dataset = ds.dataset('.', format='parquet',\n",
        "                     partitioning='hive',\n",
        "                     exclude_invalid_files=True)\n",
        "\n",
        "print(\"\\n📚 Dataset con múltiples archivos:\")\n",
        "print(f\"Archivos encontrados: {len(list(dataset.get_fragments()))}\")\n",
        "\n",
        "# Consultar el dataset completo\n",
        "tabla_completa = dataset.to_table()\n",
        "print(f\"Total de registros: {tabla_completa.num_rows}\")"
      ],
      "metadata": {
        "id": "eK-AXoX98kDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Análisis por región\n",
        "# ============================================\n",
        "print(\"\\n🌎 Análisis por región:\")\n",
        "\n",
        "for region in ['Norte', 'Sur', 'Este', 'Oeste']:\n",
        "    filtro = ds.field('region') == region\n",
        "    tabla_region = dataset.to_table(filter=filtro)\n",
        "    ingresos_region = pc.sum(tabla_region['ingresos'])\n",
        "    print(f\"{region}: {tabla_region.num_rows} ventas, ${ingresos_region.as_py():,.2f} ingresos\")"
      ],
      "metadata": {
        "id": "uT0Z9hsU8mf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Conversión a Pandas para visualización\n",
        "# ============================================\n",
        "# Convertir a Pandas para usar con matplotlib/seaborn\n",
        "df_resultado = tabla_con_ingresos.to_pandas()\n",
        "\n",
        "# Análisis por producto\n",
        "resumen_productos = df_resultado.groupby('producto').agg({\n",
        "    'cantidad': 'sum',\n",
        "    'ingresos': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\n📊 Resumen por producto:\")\n",
        "print(resumen_productos)"
      ],
      "metadata": {
        "id": "ssvfAJ5N8pTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELDA 13: Comparación de rendimiento\n",
        "# ============================================\n",
        "import time\n",
        "\n",
        "# Crear un dataset más grande\n",
        "datos_grandes = {\n",
        "    'col1': np.random.randint(0, 1000, 100000),\n",
        "    'col2': np.random.randn(100000),\n",
        "    'col3': np.random.choice(['A', 'B', 'C', 'D'], 100000)\n",
        "}\n",
        "\n",
        "df_grande = pd.DataFrame(datos_grandes)\n",
        "tabla_grande = pa.Table.from_pandas(df_grande)\n",
        "\n",
        "# Guardar en Parquet\n",
        "inicio = time.time()\n",
        "pq.write_table(tabla_grande, 'grande.parquet', compression='snappy')\n",
        "tiempo_parquet = time.time() - inicio\n",
        "\n",
        "# Guardar en CSV\n",
        "inicio = time.time()\n",
        "df_grande.to_csv('grande.csv', index=False)\n",
        "tiempo_csv = time.time() - inicio\n",
        "\n",
        "print(f\"⚡ Comparación de velocidad de escritura:\")\n",
        "print(f\"Parquet: {tiempo_parquet:.3f} segundos\")\n",
        "print(f\"CSV: {tiempo_csv:.3f} segundos\")\n",
        "print(f\"Parquet es {tiempo_csv/tiempo_parquet:.1f}x más rápido\")\n",
        "\n",
        "# Comparar tamaños\n",
        "tamaño_parquet = os.path.getsize('grande.parquet') / (1024 * 1024)\n",
        "tamaño_csv = os.path.getsize('grande.csv') / (1024 * 1024)\n",
        "\n",
        "print(f\"\\n💾 Comparación de tamaño:\")\n",
        "print(f\"Parquet: {tamaño_parquet:.2f} MB\")\n",
        "print(f\"CSV: {tamaño_csv:.2f} MB\")\n",
        "print(f\"Parquet es {tamaño_csv/tamaño_parquet:.1f}x más pequeño\")"
      ],
      "metadata": {
        "id": "349HykRe8r7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U50osudc8vw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}